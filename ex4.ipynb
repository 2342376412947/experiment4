{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入必要库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "device = torch.device('cpu') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载并预处理 MNIST 数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))  # MNIST标准归一化参数\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义 MLP 模型\n",
    "模型为两层全连接神经网络，结构：输入层（784 维，28×28 展平）→ 隐藏层（128 维，ReLU 激活）→ 输出层（10 维，对应 10 个数字）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "    def __init__(self):  # 修正初始化方法名\n",
    "        super(mlp, self).__init__()  # 修正父类初始化调用\n",
    "        self.l1 = nn.Linear(784, 128)  # 修正层命名（1→l）\n",
    "        self.l2 = nn.Linear(128, 10)   # 修正层命名（1→l）\n",
    "\n",
    "    def forward(self, x):\n",
    "        a1 = self.l1(x)\n",
    "        x1 = F.relu(a1)\n",
    "        a2 = self.l2(x1)\n",
    "        x2 = a2\n",
    "        return x2\n",
    "\n",
    "# 初始化模型、优化器\n",
    "model = mlp().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置训练参数 训练模型 测试模型\n",
    "\n",
    "训练轮次：epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:0.4949, acc:0.8696\n",
      "epoch:1, loss:0.3721, acc:0.8972\n",
      "epoch:2, loss:0.3268, acc:0.9073\n",
      "epoch:3, loss:0.2955, acc:0.9172\n",
      "epoch:4, loss:0.2766, acc:0.9193\n",
      "epoch:5, loss:0.2597, acc:0.9262\n",
      "epoch:6, loss:0.2504, acc:0.9283\n",
      "epoch:7, loss:0.2365, acc:0.9326\n",
      "epoch:8, loss:0.2260, acc:0.9357\n",
      "epoch:9, loss:0.2157, acc:0.9372\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.view(x.shape[0], -1).to(device), y.to(device)  # 展平为784维向量\n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 测试阶段\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(test_loader):\n",
    "            x, y = x.view(x.shape[0], -1).to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            test_loss += F.cross_entropy(output, y, reduction='sum').item()  # 累加批次损失\n",
    "            pred = output.max(1, keepdim=True)[1]  # 取概率最大的类别\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()  # 统计正确预测数\n",
    "\n",
    "    # 计算平均测试损失和准确率\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "    print('epoch:{}, loss:{:.4f}, acc:{:.4f}'.format(epoch, test_loss, acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
